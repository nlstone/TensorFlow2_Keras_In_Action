{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_divices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据加载\n",
    "(image_train, label_train),\\\n",
    "(image_test, label_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据归一化\n",
    "image_train_normalize = image_train / 255\n",
    "image_test_normalize = image_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train_onehot = keras.utils.to_categorical(label_train)\n",
    "label_test_onehot = keras.utils.to_categorical(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 1, 1, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 14,752,330\n",
      "Trainable params: 14,752,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "vgg16 = keras.applications.VGG16(include_top=False, input_shape=(32,32,3), weights='imagenet')\n",
    "    \n",
    "model.add( vgg16 )\n",
    "model.add( keras.layers.Flatten() )\n",
    "model.add( keras.layers.Dense(64, activation='relu') )\n",
    "model.add( keras.layers.Dense(64, activation='relu') )\n",
    "model.add( keras.layers.Dense(10, activation='softmax') )\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "# sparse_categorical_crossentropy ?\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 391 steps, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 34s 86ms/step - loss: 1.9972 - categorical_accuracy: 0.2046 - val_loss: 1.8677 - val_categorical_accuracy: 0.2535\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 26s 68ms/step - loss: 1.6293 - categorical_accuracy: 0.3620 - val_loss: 1.3242 - val_categorical_accuracy: 0.4824\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 26s 68ms/step - loss: 1.2878 - categorical_accuracy: 0.5259 - val_loss: 1.0743 - val_categorical_accuracy: 0.6181\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 26s 68ms/step - loss: 1.0956 - categorical_accuracy: 0.6142 - val_loss: 1.0683 - val_categorical_accuracy: 0.6463\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 27s 68ms/step - loss: 0.9595 - categorical_accuracy: 0.6718 - val_loss: 0.9862 - val_categorical_accuracy: 0.6771\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 27s 68ms/step - loss: 0.8789 - categorical_accuracy: 0.7049 - val_loss: 0.7702 - val_categorical_accuracy: 0.7473\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 27s 68ms/step - loss: 0.8012 - categorical_accuracy: 0.7340 - val_loss: 0.7543 - val_categorical_accuracy: 0.7507\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 27s 68ms/step - loss: 0.7598 - categorical_accuracy: 0.7473 - val_loss: 0.6680 - val_categorical_accuracy: 0.7817\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.7163 - categorical_accuracy: 0.7619 - val_loss: 0.7381 - val_categorical_accuracy: 0.7676\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.6884 - categorical_accuracy: 0.7713 - val_loss: 0.6679 - val_categorical_accuracy: 0.7827\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.6514 - categorical_accuracy: 0.7880 - val_loss: 0.7700 - val_categorical_accuracy: 0.7684\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.6260 - categorical_accuracy: 0.7940 - val_loss: 0.7027 - val_categorical_accuracy: 0.7860\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.6019 - categorical_accuracy: 0.8037 - val_loss: 0.6182 - val_categorical_accuracy: 0.8021\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.5861 - categorical_accuracy: 0.8082 - val_loss: 0.6302 - val_categorical_accuracy: 0.8005\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.5728 - categorical_accuracy: 0.8116 - val_loss: 0.5741 - val_categorical_accuracy: 0.8172\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.5480 - categorical_accuracy: 0.8201 - val_loss: 0.6234 - val_categorical_accuracy: 0.8109\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.5351 - categorical_accuracy: 0.8264 - val_loss: 0.5812 - val_categorical_accuracy: 0.8190\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.5105 - categorical_accuracy: 0.8327 - val_loss: 0.5907 - val_categorical_accuracy: 0.8160\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.5051 - categorical_accuracy: 0.8354 - val_loss: 0.5523 - val_categorical_accuracy: 0.8259\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.4936 - categorical_accuracy: 0.8387 - val_loss: 0.5472 - val_categorical_accuracy: 0.8294\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.4808 - categorical_accuracy: 0.8415 - val_loss: 0.5446 - val_categorical_accuracy: 0.8324\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.4731 - categorical_accuracy: 0.8462 - val_loss: 0.5162 - val_categorical_accuracy: 0.8366\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.4623 - categorical_accuracy: 0.8490 - val_loss: 0.4983 - val_categorical_accuracy: 0.8448\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.4595 - categorical_accuracy: 0.8491 - val_loss: 0.4815 - val_categorical_accuracy: 0.8489\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.4428 - categorical_accuracy: 0.8544 - val_loss: 0.5009 - val_categorical_accuracy: 0.8458\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.4430 - categorical_accuracy: 0.8554 - val_loss: 0.5149 - val_categorical_accuracy: 0.8435\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.4183 - categorical_accuracy: 0.8632 - val_loss: 0.4623 - val_categorical_accuracy: 0.8529\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.4190 - categorical_accuracy: 0.8617 - val_loss: 0.5083 - val_categorical_accuracy: 0.8369\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.4030 - categorical_accuracy: 0.8687 - val_loss: 0.4925 - val_categorical_accuracy: 0.8469\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.4018 - categorical_accuracy: 0.8680 - val_loss: 0.4945 - val_categorical_accuracy: 0.8522\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.3895 - categorical_accuracy: 0.8713 - val_loss: 0.4521 - val_categorical_accuracy: 0.8617\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.3858 - categorical_accuracy: 0.8743 - val_loss: 0.4876 - val_categorical_accuracy: 0.8502\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 0.3897 - categorical_accuracy: 0.8740 - val_loss: 0.4600 - val_categorical_accuracy: 0.8659\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.3794 - categorical_accuracy: 0.8769 - val_loss: 0.4780 - val_categorical_accuracy: 0.8565\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.3769 - categorical_accuracy: 0.8770 - val_loss: 0.5013 - val_categorical_accuracy: 0.8556\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.3667 - categorical_accuracy: 0.8804 - val_loss: 0.4520 - val_categorical_accuracy: 0.8563\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.3668 - categorical_accuracy: 0.8832 - val_loss: 0.5275 - val_categorical_accuracy: 0.8475\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.3522 - categorical_accuracy: 0.8852 - val_loss: 0.4794 - val_categorical_accuracy: 0.8522\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.3459 - categorical_accuracy: 0.8868 - val_loss: 0.4925 - val_categorical_accuracy: 0.8642\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.3430 - categorical_accuracy: 0.8890 - val_loss: 0.4098 - val_categorical_accuracy: 0.8782\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.3465 - categorical_accuracy: 0.8888 - val_loss: 0.4957 - val_categorical_accuracy: 0.8599\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.3366 - categorical_accuracy: 0.8906 - val_loss: 0.4998 - val_categorical_accuracy: 0.8559\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.3395 - categorical_accuracy: 0.8900 - val_loss: 0.5298 - val_categorical_accuracy: 0.8484\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.3278 - categorical_accuracy: 0.8940 - val_loss: 0.4459 - val_categorical_accuracy: 0.8660\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.3293 - categorical_accuracy: 0.8941 - val_loss: 0.4931 - val_categorical_accuracy: 0.8631\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.3223 - categorical_accuracy: 0.8969 - val_loss: 0.5018 - val_categorical_accuracy: 0.8594\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.3150 - categorical_accuracy: 0.8989 - val_loss: 0.4952 - val_categorical_accuracy: 0.8584\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 27s 69ms/step - loss: 0.3106 - categorical_accuracy: 0.8988 - val_loss: 0.4392 - val_categorical_accuracy: 0.8743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "391/391 [==============================] - 27s 68ms/step - loss: 0.3131 - categorical_accuracy: 0.8981 - val_loss: 0.4043 - val_categorical_accuracy: 0.8836\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 27s 68ms/step - loss: 0.3127 - categorical_accuracy: 0.8982 - val_loss: 0.4648 - val_categorical_accuracy: 0.8654\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "imgGenerator = keras.preprocessing.image.ImageDataGenerator(\n",
    "                        rotation_range=5,\n",
    "                        shear_range=1,\n",
    "                        width_shift_range=0.2,\n",
    "                        height_shift_range=0.2,\n",
    "                        horizontal_flip=True,\n",
    "                        vertical_flip=False,\n",
    "                        zoom_range=0.2,\n",
    "                        fill_mode='nearest')\n",
    "\n",
    "gen = imgGenerator.flow(image_train_normalize, label_train_onehot, batch_size=128)\n",
    "history = model.fit(x=gen,validation_data=(image_test_normalize, label_test_onehot), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
